{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.utils.training import *\n",
    "from src.scripts.load_and_save import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mloscratch/homes/sallinen/embeddings/src/scripts/load_and_save.py:18: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file, sep='\\t', on_bad_lines='skip', usecols=[\"Ligand SMILES\",\n"
     ]
    }
   ],
   "source": [
    "affinity = \"IC50 (nM)\"\n",
    "data = load_data_direct(affinity=affinity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ligands: 1269428\n",
      "Proportion of data: 0.43360571715690177\n"
     ]
    }
   ],
   "source": [
    "unique_ligands = data[\"ligand\"].unique()\n",
    "print(f\"Unique ligands: {len(unique_ligands)}\")\n",
    "print(f\"Proportion of data: {len(unique_ligands) / len(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_grams = parallel_ngrams(data)\n",
    "ligands_atoms = atom_set(data[\"ligand\"])\n",
    "total_vocabulary = build_vocab(common_grams, ligands_atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.pre_tokenizers import Split\n",
    "from tokenizers import Regex\n",
    "\n",
    "escaped_tokens = [re.escape(token) for token in total_vocabulary]\n",
    "pattern = '|'.join(sorted(escaped_tokens, key=len, reverse=True))\n",
    "preTokenizer = Split(Regex(pattern), behavior='isolated')\n",
    "preTokenizer.pre_tokenize_str('CC(=O)O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = generate_tokenizer(data, preTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(\"models/tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"models/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length: 2115\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "maximum_length = max([len(smiles) for smiles in data[\"ligand\"]])\n",
    "print(f\"Maximum length: {maximum_length}\")\n",
    "\n",
    "\n",
    "\n",
    "plt.hist([len(smiles) for smiles in data[\"ligand\"] if len(smiles) < 1024], bins=50)\n",
    "plt.hist([len(smiles) for smiles in data[\"ligand\"]], bins=50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] CC (=O) O [SEP] CC cc [SEP]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(\"CC(=O)O\", \"CCcc\", add_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The fast path is not available because one of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the sequential implementation of Mamba, as use_mambapy is set to False. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d. For the mamba.py backend, follow https://github.com/alxndrTL/mamba.py.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 100\n",
      "Number of parameters: 706816\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model, data_collator = generate_model(tokenizer, max_in_size=512, multiplier=1)\n",
    "#pretty print the number\n",
    "print(f\"Number of parameters: {model.num_parameters()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing SMILES: 100%|██████████| 1269428/1269428 [02:07<00:00, 9945.94it/s] \n",
      "Saving the dataset (2/2 shards): 100%|██████████| 1269428/1269428 [00:01<00:00, 974296.37 examples/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1269428\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = tokenize_smiles_dataset(data, tokenizer, model.config.max_position_embeddings)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1269428\n",
      "2927609\n"
     ]
    }
   ],
   "source": [
    "print(len(tokenized_dataset))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1269428\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = Dataset.load_from_disk(\"data/tokenized_dataset\")\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear cuda cache and gc\n",
    "import torch\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "#Drop label column\n",
    "tokenized_dataset = tokenized_dataset.remove_columns(\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:323: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='773' max='2480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 773/2480 3:17:40 < 7:17:40, 0.07 it/s, Epoch 0.31/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>39.641100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.958600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.406100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.951700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.771000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.656800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.607400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.553300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.523700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.508000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.460900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.431700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.418400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.408200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.393600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.365100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.365400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.359100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.341400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.339800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.305500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.320100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.302200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.311100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.280200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.286800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.297900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.276600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.268400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.257100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.258900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.259200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.253700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.248400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.251500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.243500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.236700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.235100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.223400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.228900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.219700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.226600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.224100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.222700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.212500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.201900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.195500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.207100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.191700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.200700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.184800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.195800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.183900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.170800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.184900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.189500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.186500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.186700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.186300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>1.179400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.183300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.161200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.174100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.167500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.177500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.153600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.169500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.161900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.174100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.155200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.161500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>1.152900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.150800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.161700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>1.144200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer, logs = train_fundation(model, tokenizer, data_collator, tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the affinity column contians nan values and may contain other values that are not numbers. Clean the data\n",
    "print(data.isna().sum() / len(data)) \n",
    "data_filtered = data.dropna(subset=[\"affinity\"])\n",
    "print(data_filtered.isna().sum() / len(data_filtered)) \n",
    "data_filtered = data_filtered.dropna(subset=[\"target\"])\n",
    "print(data_filtered.isna().sum() / len(data_filtered)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_list([{\"text\": ligand} for ligand in ligands])\n",
    "tokenized_dataset = dataset.map(preprocess, batched=True, remove_columns=[\"text\"], batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tokenised dataset\n",
    "tokenized_dataset.save_to_disk(\"data/tokenized_dataset\")\n",
    "# save tokenizer\n",
    "fast_tokenizer.save_pretrained(\"data/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fast_tokenizer = AutoTokenizer.from_pretrained(\"data/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "from transformers import MambaForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = MambaForCausalLM.from_pretrained(\"./mamba-smiles/checkpoint-2000\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./mamba-smiles/checkpoint-2000\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'generated_text': 'CC(=O)O [C@H] 2'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Generate some SMILES\n",
    "smiles = generator(\"CC(=O)O\", max_length=512, \n",
    "                   temperature=0.5, \n",
    "                   num_return_sequences=5,\n",
    "                   num_beams=5,  # Use beam search to generate multiple sequences\n",
    "                   top_k=50, top_p=0.95)\n",
    "\n",
    "smiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ic = Dataset.load_from_disk(\"data/ic50_dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
